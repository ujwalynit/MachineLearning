{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joseph.ujwal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:101: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\joseph.ujwal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\joseph.ujwal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\joseph.ujwal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:104: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\joseph.ujwal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:105: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\joseph.ujwal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "#######################  1. LOAD THE TRAINING TEXT  ###########################\n",
    "###############################################################################\n",
    "with open(\"../data/reviews.txt\") as f:\n",
    "    reviews = f.read()\n",
    "    \n",
    "with open(\"../data/labels.txt\") as f:\n",
    "    labels = f.read()\n",
    "    \n",
    "\n",
    "###############################################################################\n",
    "##########################  2. TEXT PRE-PROCESSING  ###########################\n",
    "###############################################################################\n",
    "import string\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text=text.translate(str.maketrans('', '', string.punctuation))\n",
    "    all_reviews = text.split(\"\\n\")\n",
    "    text =text.split()\n",
    "    text=\" \".join(text)\n",
    "    all_words = text.split(' ')\n",
    "    return all_reviews, all_words\n",
    "\n",
    "all_reviews, all_words  = preprocess(reviews)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "##################  3. CREATE DICTIONARIES & ENCODE REVIEWS  ##################\n",
    "###############################################################################\n",
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter(all_words)\n",
    "word_list = sorted(word_counts, key = word_counts.get, reverse = True)\n",
    "vocab_to_int = {word:idx+1 for idx, word in enumerate(word_list)}\n",
    "int_to_vocab = {idx:word for word, idx in vocab_to_int.items()}\n",
    "encoded_reviews = [[vocab_to_int[word] for word in review.split()] for review in all_reviews]\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#############################  4. ENCODE LABELS ###############################\n",
    "###############################################################################\n",
    "all_labels = labels.split(\"\\n\")\n",
    "encoded_labels = [1 if label == \"positive\" else 0 for label in all_labels]\n",
    "assert len(encoded_reviews) == len(encoded_labels), \"# of encoded reivews & encoded labels must be the same!\"\n",
    "\n",
    "###############################################################################\n",
    "#####################  5. GET RID OF LENGTH-0 REVIEWS   #######################\n",
    "###############################################################################\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "encoded_labels = np.array( [label for idx, label in enumerate(encoded_labels) if len(encoded_reviews[idx]) > 0] )\n",
    "encoded_reviews = [review for review in encoded_reviews if len(review) > 0]\n",
    "\n",
    "###############################################################################\n",
    "######################  6. MAKE ALL REVIEWS SAME LENGTH  #######################\n",
    "###############################################################################\n",
    "def pad_text(encoded_reviews, seq_length):\n",
    "    \n",
    "    reviews = []\n",
    "    \n",
    "    for review in encoded_reviews:\n",
    "        if len(review) >= seq_length:\n",
    "            reviews.append(review[:seq_length])\n",
    "        else:\n",
    "            reviews.append([0]*(seq_length-len(review)) + review)\n",
    "        \n",
    "    return np.array(reviews)\n",
    "\n",
    "\n",
    "padded_reviews = pad_text(encoded_reviews, seq_length = 200)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "##############  7.SPLIT DATA & GET (REVIEW, LABEL) DATALOADER  ###############\n",
    "###############################################################################\n",
    "train_ratio = 0.8\n",
    "valid_ratio = (1 - train_ratio)/2\n",
    "total = padded_reviews.shape[0]\n",
    "train_cutoff = int(total * train_ratio)\n",
    "valid_cutoff = int(total * (1 - valid_ratio))\n",
    "\n",
    "train_x, train_y = padded_reviews[:train_cutoff], encoded_labels[:train_cutoff]\n",
    "valid_x, valid_y = padded_reviews[train_cutoff : valid_cutoff], encoded_labels[train_cutoff : valid_cutoff]\n",
    "test_x, test_y = padded_reviews[valid_cutoff:], encoded_labels[valid_cutoff:]\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd \n",
    "device =\"cpu\" ## DEFAULTING DEVICE TO CPU\n",
    "\n",
    "train_x = torch.from_numpy(train_x)\n",
    "train_y = torch.from_numpy(train_y)\n",
    "valid_x = torch.from_numpy(valid_x)\n",
    "valid_y = torch.from_numpy(valid_y)\n",
    "test_x = torch.from_numpy(test_x)\n",
    "test_y = torch.from_numpy(test_y)\n",
    "\n",
    "train_x= torch.tensor(train_x).to(device).long()\n",
    "train_y= torch.tensor(train_y).to(device).long()\n",
    "valid_x= torch.tensor(valid_x).to(device).long()\n",
    "valid_y= torch.tensor(valid_y).to(device).long()\n",
    "test_x= torch.tensor(train_x).to(device).long()\n",
    "test_y= torch.tensor(train_x).to(device).long()\n",
    "\n",
    "train_data = TensorDataset(train_x, train_y)\n",
    "valid_data = TensorDataset(valid_x, valid_y)\n",
    "test_data = TensorDataset(test_x, test_y)\n",
    "\n",
    "batch_size = 50\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#########################  8.DEFINE THE LSTM MODEL  ##########################\n",
    "###############################################################################\n",
    "from torch import nn\n",
    "\n",
    "class SentimentNet(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super(SentimentNet, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size) #fully connected \n",
    "        self.sigmoid = nn.Sigmoid()        \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        out = out.view(batch_size, -1)\n",
    "        out = out[:,-1]\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "############ 9.PARAMETER INITIALIZATON ##########################################\n",
    "###############################################################################\n",
    "vocab_size = len(vocab_to_int) + 1\n",
    "output_size = 1\n",
    "embedding_dim = 200\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "\n",
    "model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "model.to(device)\n",
    "\n",
    "lr=0.005\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "############ 10.TRAINING ######################################################\n",
    "###############################################################################\n",
    "\n",
    "epochs = 10\n",
    "counter = 0\n",
    "print_every = 1000\n",
    "clip = 5\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    h = model.init_hidden(batch_size)\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        h = tuple([e.data for e in h])\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.zero_grad()\n",
    "        output, h = model(inputs, h)\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if counter%print_every == 0:\n",
    "            val_h = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for inp, lab in val_loader:\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                inp, lab = inp.to(device), lab.to(device)\n",
    "                out, val_h = model(inp, val_h)\n",
    "                val_loss = criterion(out.squeeze(), lab.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "            model.train()\n",
    "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "            if np.mean(val_losses) <= valid_loss_min:\n",
    "                torch.save(model.state_dict(), './state_dict.pt')\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
    "                valid_loss_min = np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "############11.LOADING THE BEST MODEL AND TEST THE TRAINED MODEL ON TEST SET####\n",
    "################################################################################\n",
    "model.load_state_dict(torch.load('./state_dict.pt'))\n",
    "\n",
    "test_losses = []\n",
    "num_correct = 0\n",
    "h = model.init_hidden(batch_size)\n",
    "\n",
    "model.eval()\n",
    "for inputs, labels in test_loader:\n",
    "    h = tuple([each.data for each in h])\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    output, h = model(inputs, h)\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    pred = torch.round(output.squeeze())  # Rounds the output to 0/1\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "############  TEST THE TRAINED MODEL ON A RANDOM SINGLE REVIEW ################\n",
    "###############################################################################\n",
    "def predict(net, review, seq_length = 200):\n",
    "    device = \"cpu\"\n",
    "    \n",
    "    text, words = preprocess(review)\n",
    "    encoded_words = [vocab_to_int[word] for word in words]\n",
    "    padded_words = pad_text([encoded_words], seq_length)\n",
    "    padded_words = torch.from_numpy(padded_words).to(device)\n",
    "    \n",
    "    if(len(padded_words) == 0):\n",
    "        \"Your review must contain at least 1 word!\"\n",
    "        return None\n",
    "    \n",
    "    net.eval()\n",
    "    h = net.init_hidden(1)\n",
    "    output, h = net(padded_words, h)\n",
    "    pred = torch.round(output.squeeze())\n",
    "    msg = \"This is a positive review.\" if pred == 0 else \"This is a negative review.\"\n",
    "    \n",
    "    return msg\n",
    "\n",
    "\n",
    "review1 = \"It made me cry.\"\n",
    "review2 = \"It was so good it made me cry.\"\n",
    "review3 = \"It's ok.\"\n",
    "review4 = \"This movie had the best acting and the dialogue was so good. I loved it.\"\n",
    "review5 = \"Garbage\"\n",
    "                       ### OUTPUT ###\n",
    "predict(net, review1)  ## negative ##\n",
    "predict(net, review2)  ## positive ##\n",
    "predict(net, review3)  ## negative ##\n",
    "predict(net, review4)  ## positive ##\n",
    "predict(net, review5)  ## negative ##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
